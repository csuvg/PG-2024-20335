\section{Lensegua}

\subsection{¿Qué es Lensegua?}
En Guatemala, el Lenguaje de Señas Guatemalteco (Lensegua) se oficializó el 18 de febrero de 2020 con el Decreto 3-2020. Este decreto regula la aprobación, desarrollo, uso y fomento de Lensegua, asegurando su reconocimiento y promoción en el país. 

``Lengua de señas de Guatemala. Es la lengua oficial para poder comunicarse en lengua de señas en Guatemala (según Decreto 3-2020)" \cite{Lensegua}.

\subsection{Historia de Lensegua}
En Guatemala, la comunidad sorda comenzó a desarrollar sus propios signos y métodos de comunicación, adaptando movimientos, posiciones y representaciones de letras a sus necesidades culturales y sociales. Este proceso fue orgánico, impulsado por la interacción diaria y la necesidad de comunicación efectiva dentro de la comunidad.

El reconocimiento oficial de Lensegua llegó el 18 de febrero de 2020, con la promulgación del Decreto 3-2020. Este decreto estableció la regulación para la aprobación, desarrollo, uso y fomento de la Lengua de Señas de Guatemala. Con esta legislación, el gobierno guatemalteco no solo reconoció la importancia de Lensegua, sino que también se comprometió a promover su enseñanza y uso en todo el país, asegurando que la comunidad sorda tenga acceso a una forma de comunicación efectiva y respetada. La implementación de Lensegua ha sido un hito significativo para la inclusión y el reconocimiento de los derechos de las personas sordas en Guatemala, marcando un paso crucial hacia una sociedad más inclusiva y equitativa \cite{LenseguaHistoria}.

\section{Sistema Operativo: Linux Server}

\subsection{¿Qué es Linux?}
Linux es un sistema operativo de código abierto basado en Unix que se ha establecido como una opción poderosa y versátil para una variedad de plataformas, desde servidores y supercomputadoras hasta dispositivos móviles y electrodomésticos. Fue creado inicialmente por Linus Torvalds en 1991. El núcleo de Linux, conocido como el kernel, gestiona las interacciones del software con el hardware y es vital para la regulación de los recursos del sistema. A lo largo de los años, Linux ha ganado una popularidad masiva, en parte debido a su naturaleza de código abierto, que permite a los usuarios modificar y mejorar su software según necesiten. Además, su alta configurabilidad, estabilidad y robustez en seguridad lo hacen preferido en entornos empresariales y académicos. La comunidad de Linux es una de sus mayores fortalezas, contribuyendo constantemente con una amplia gama de distribuciones adaptadas a diferentes usos y preferencias \cite{Linux}.

\subsection{Historia de Linux}
Linux es un sistema operativo de código abierto creado en 1991 por Linus Torvalds, un estudiante de la Universidad de Helsinki. Inspirado en Unix, Torvalds deseaba ofrecer una alternativa gratuita y accesible, por lo que liberó Linux bajo la Licencia Pública General de GNU para permitir su uso, modificación y redistribución libre. Inicialmente adoptado por entusiastas tecnológicos y desarrolladores, Linux ha evolucionado hasta ser ampliamente utilizado en servidores, dispositivos móviles y supercomputadoras. Destacado por su estabilidad, seguridad y flexibilidad, es ahora uno de los sistemas operativos más predominantes a nivel mundial, con múltiples distribuciones como Ubuntu, Fedora y Arch que facilitan su uso en una gran variedad de entornos \cite{HistoriaLinux}.

\subsection{Linux Server}
Un servidor Linux se compone fundamentalmente de Linux, una familia de sistemas operativos de software libre y código abierto que se desarrollan alrededor del kernel de Linux. Originalmente creado como una versión alternativa y libre del sistema operativo MINIX, los servidores Linux se han popularizado gracias a su estabilidad, seguridad y flexibilidad. Estas características no solo los diferencian de sus contrapartes propietarias, sino que también mantienen bajos los costos de configuración y mantenimiento. Además, ofrecen una flexibilidad aumentada en la configuración, operación y mantenimiento de un servidor. Un sistema operativo de servidor Linux proporciona la interfaz central para la gestión de usuarios e implementa diversos servicios de seguridad y administración, todos cruciales para operar en una arquitectura cliente-servidor \cite{LinuxServer}.

\section{Virtualización}
La virtualización, en el contexto de la computación, implica la creación de versiones virtuales de recursos que originalmente eran físicos, como sistemas operativos y hardware de red. Este proceso permite a un solo servidor físico alojar múltiples máquinas virtuales (VMs), cada una con su propio sistema operativo y aplicaciones, operando de manera independiente pero compartiendo los recursos subyacentes del hardware físico \cite{Virtualizacion}.

El propósito principal de la virtualización fue maximizar la eficiencia del uso de recursos al permitir que múltiples sistemas operativos y aplicaciones se ejecutaran en un solo servidor físico. Esto no solo reduce los costos de hardware, sino que también aumenta la flexibilidad y la escalabilidad de los sistemas de TI. Las VMs pueden migrar entre servidores con mínimo tiempo de inactividad, lo que facilita el mantenimiento y la gestión del sistema \cite{Virtualizacion2}.

\section{Multipass}
Multipass es una herramienta ligera de virtualización diseñada para facilitar la creación y gestión de máquinas virtuales, enfocada especialmente en entornos de desarrollo y pruebas rápidas. Al integrarse de manera nativa con Ubuntu, Multipass permite desplegar y administrar múltiples instancias de Linux de manera eficiente, actuando como una mini-nube local en tu propio equipo. Multipass ha sido desarrollado con la simplicidad en mente, proporcionando una experiencia optimizada para usuarios que necesitan acceder rápidamente a entornos virtuales consistentes sin la complejidad de configuraciones avanzadas \cite{Multipass}.

\section{VPN}
\subsection{¿Qué es una VPN?}
Una VPN (red privada virtual) establece una conexión segura y privada entre dispositivos a través de Internet. Este tipo de red es fundamental para la transmisión de datos de manera segura y anónima a través de infraestructuras públicas. El proceso implica enmascarar las direcciones IP de los usuarios y cifrar la información transmitida, asegurando que solo las partes autorizadas puedan acceder y leer estos datos \cite{VPN}.

\subsection{¿Para qué sirven las VPNs?}
Las VPNs, o redes privadas virtuales, son esenciales para permitir conexiones remotas seguras a servidores y recursos de red. OpenVPN, un destacado software de VPN de código abierto, facilitó el establecimiento de redes locales virtuales entre computadoras dispersas geográficamente, permitiendo a los usuarios acceder y operar servidores y datos como si estuvieran físicamente presentes en la misma red local. Esto es crucial para empresas y organizaciones con equipos distribuidos, asegurando que la comunicación y el acceso a recursos críticos sean seguros y eficientes \cite{OpenVPN}.

\section{Arquitectura de base de datos}
\subsection{Bases de datos relacionales}
Una base de datos relacional es una estructura que organiza la información en filas y columnas dentro de tablas, facilitando el almacenamiento, la búsqueda y la gestión de datos de manera eficiente. Las tablas se enlazan entre sí mediante claves primarias y claves foráneas, creando relaciones que reflejan cómo se conectan los datos en diferentes tablas. Este sistema permite a los usuarios emplear consultas SQL para cruzar información de diversas tablas, proporcionando una herramienta poderosa para analizar y resumir el rendimiento empresarial \cite{Relacionales}.

\subsection{PostgreSQL}
PostgreSQL es una mejora del sistema de gestión Postgres, un prototipo avanzado de DBMS de próxima generación. Mientras conserva el modelo de datos potente y los tipos de datos ricos de Postgres, PostgreSQL ha reemplazado el lenguaje de consulta POSTQUEL por un subconjunto extendido de SQL, convirtiéndolo en una opción gratuita y de código abierto para el manejo de bases de datos. Desarrollado inicialmente en la Universidad de California en Berkeley, PostgreSQL ha evolucionado significativamente gracias a la contribución de un equipo de desarrolladores a nivel mundial \cite{Postgres}.

\subsection{Arquitectura de base de datos}
La arquitectura de datos se refiere al diseño estructural y a la metodología empleada para organizar y gestionar los recursos de datos en una organización o sistema. Este marco establece las políticas, normas y procedimientos para la recopilación, almacenamiento, manejo y uso de los datos con el fin de asegurar su accesibilidad, consistencia, integridad y seguridad. Una arquitectura de datos eficaz apoya la estrategia de información de una empresa, facilitando la integración y la operación de sistemas de TI, mejorando el soporte para las decisiones basadas en datos y optimizando el rendimiento de las aplicaciones \cite{ArquitecturaDatos}.

\section{APIs}
\subsection{¿Qué es una API?}
Una API (Interfaz de Programación de Aplicaciones) es un conjunto de reglas y especificaciones que las aplicaciones pueden seguir para comunicarse entre sí. Funciona como un puente que permite la interacción entre diferentes piezas de software de manera estandarizada. Por ejemplo, una aplicación de pronóstico del tiempo puede recibir datos de un servicio meteorológico utilizando una API para comunicarse con el sistema de dicho servicio \cite{API}.

\subsection{¿Cómo usar una API?}
Usar una API a nivel básico implica interactuar con un conjunto de definiciones y protocolos que permiten la comunicación entre diferentes componentes de software. Primero, es esencial entender los métodos estándar que la API ofrece, como obtener, crear, actualizar o eliminar recursos. Cada interacción sigue un patrón predefinido, facilitando así la integración y uso de la API en proyectos \cite{UsoAPI}.

\subsection{Implementar APIs a bases de datos}
Al desarrollar una aplicación que necesite interactuar con una base de datos mediante una API, puedes realizar operaciones como crear, recuperar, actualizar o eliminar registros. Estas operaciones se definen claramente con ciertos parámetros de entrada esperados y formatos de respuesta, lo que facilita la integración de sistemas complejos \cite{ImplementarAPI}.

\subsection{Implementar APIs para recepción y devolución de datos}
El uso de una API para enviar y recibir información implica interacciones estructuradas mediante solicitudes y respuestas definidas. Un ejemplo común es usar un método HTTP POST para enviar datos a la API, que luego devuelve una respuesta indicando éxito o fallo \cite{ImplementarAPIDatos}.

\subsection{¿Qué es Crontab?}
`Crontab` es una herramienta en sistemas Unix/Linux que permite la programación de tareas automatizadas que se ejecutan a intervalos específicos. Estas tareas, conocidas como cron jobs, son útiles para ejecutar scripts y comandos de forma recurrente sin intervención manual, lo cual es ideal para tareas de mantenimiento o procesamiento automatizado, como el reinicio de rachas en nuestra aplicación \cite{HostingerCrontabTutorial}.

\section{Bases de diseño y filosofía de DARPA}
Entre los conceptos fundamentales aplicados en el diseño de la arquitectura del sistema, se adoptaron varios principios expuestos en el documento "The Design Philosophy of the DARPA Internet Protocols" \cite{DARPA}. A continuación, se destacan los siguientes conceptos clave:

\subsection{Costo-efectividad y control}
La arquitectura de Internet, según lo planteado por DARPA, enfatiza la necesidad de manejar los recursos de manera eficaz bajo control administrativo distribuido. Esto justifica la decisión de utilizar servidores propios en lugar de servicios en la nube para este proyecto, reduciendo dependencias externas y costos operativos. Al mantener un control directo sobre la infraestructura, se puede gestionar de manera más eficiente el uso de los recursos, optimizando la relación costo-beneficio sin sacrificar el rendimiento.

\subsection{Flexibilidad y adaptabilidad}
La filosofía de diseño también subraya la importancia de adaptarse a diferentes entornos y requisitos técnicos. En este proyecto, la elección de Ubuntu como sistema operativo refleja un compromiso con un sistema flexible y robusto, ya que permite una personalización extensa. Aunque inicialmente se consideró el uso de RAID para la gestión del almacenamiento, se decidió desinstalarlo y desconfigurarlo debido a las limitaciones específicas del entorno de este proyecto. Esto asegura que la infraestructura sea adaptable a las necesidades actuales, manteniendo un enfoque simplificado en la gestión de recursos.

\subsection{Seguridad y privacidad}
Siguiendo los principios de diseño de DARPA, la seguridad es una prioridad fundamental. La integridad y seguridad de la comunicación entre los sistemas es vital para el éxito del proyecto. En este sentido, la implementación de una VPN segura mediante OpenVPN garantiza la protección de los datos transmitidos, asegurando que el acceso remoto y la transferencia de información se realicen de manera segura y confiable, reduciendo el riesgo de vulnerabilidades y ataques.

\section{Pruebas de eficiencia y de extremo a extremo en el servidor mediante APIs}

\subsection{¿Qué es una prueba de eficiencia?}
Las pruebas de eficiencia miden cómo el servidor responde bajo condiciones de carga habitual, evaluando aspectos como el tiempo de respuesta, la utilización de recursos (CPU, memoria y disco), y la capacidad del sistema para gestionar solicitudes simultáneas sin afectar negativamente el rendimiento. Estas pruebas permiten identificar oportunidades de optimización y ajustar la infraestructura para garantizar un rendimiento óptimo en condiciones normales de operación \cite{E2ETestingOverview}.

\subsection{¿Qué es una prueba de extremo a extremo (E2E)?}
Las pruebas de extremo a extremo (E2E) verifican el funcionamiento integral de la aplicación, evaluando cómo interactúan todos sus componentes en un flujo completo desde el punto de vista del usuario. Estas pruebas son esenciales para asegurarse de que cada parte de la aplicación, incluidas las APIs, funcione como se espera y que todos los puntos de interacción respondan adecuadamente dentro del sistema.

\begin{itemize}
    \item \textbf{Objetivo:} Confirmar que todas las partes de la aplicación operan de manera integrada, verificando que los flujos de trabajo completos (como registro, autenticación, envío de datos y consulta de información) se ejecuten sin errores.
    \item \textbf{Resultado esperado:} Que la aplicación realice todas las operaciones y flujos clave sin problemas, asegurando que cada funcionalidad principal esté correctamente integrada y funcione en conjunto.
\end{itemize}

\subsection{Impacto de la eficiencia y de las pruebas de extremo a extremo en el servidor}

\begin{itemize}
    \item \textbf{Eficiencia:} Un servidor eficiente maximiza el uso de los recursos disponibles, lo que permite reducir los costos operativos y mantener un rendimiento constante. Esto es esencial para asegurar tiempos de respuesta rápidos y garantizar que el sistema pueda manejar múltiples solicitudes concurrentes sin una degradación del servicio.

    \item \textbf{Pruebas E2E:} Las pruebas de extremo a extremo permiten validar el flujo completo de operaciones, asegurando que cada componente del sistema funcione correctamente y en sincronía. Estas pruebas ayudan a identificar cualquier posible problema de integración entre APIs y otros módulos de la aplicación, lo que es esencial para una experiencia de usuario fluida y un sistema robusto.
\end{itemize}

\section{Herramientas para pruebas de eficiencia y de extremo a extremo}

Para realizar las pruebas de eficiencia y extremo a extremo, se emplearon las siguientes herramientas:

\begin{itemize}
    \item \textbf{Python:} Se utilizó para desarrollar scripts personalizados que permiten simular múltiples usuarios y escenarios de carga en la aplicación, evaluando el tiempo de respuesta, el rendimiento y el uso de recursos en situaciones de carga típica y bajo prueba de integración completa \cite{PythonTesting}.
    \item \textbf{NGINX Amplify:} Herramienta de monitoreo utilizada para supervisar el uso de recursos en tiempo real, como CPU, memoria y tráfico de red. NGINX Amplify proporciona métricas detalladas y facilita el análisis de rendimiento durante las pruebas, identificando posibles áreas de optimización y problemas de integración \cite{NGINXAmplifyMonitoring}.
\end{itemize}

\subsection{Monitoreo del sistema}
\begin{itemize}
    \item \textbf{htop}: Proporciona una vista en tiempo real del uso de CPU, memoria y procesos en ejecución.
    \item \textbf{dstat}: Genera estadísticas combinadas de CPU, disco, memoria y red.
    \item \textbf{iotop}: Muestra el uso de disco por cada proceso, facilitando la identificación de procesos que consumen muchos recursos.
    \item \textbf{Prometheus}: Sistema de monitorización para métricas a gran escala.
    \item \textbf{Prometheus-Exporter}: Herramienta para monitorear las solicitudes entrantes al servidor.
    \item \textbf{Grafana}: Plataforma de visualización de métricas, utilizada para analizar los resultados de Prometheus \cite{MonitoringTools}.
\end{itemize}

\subsection{Pruebas de carga y end to end}

Las pruebas de carga se centran en medir la respuesta del sistema bajo condiciones de uso previstas, simulando múltiples usuarios y solicitudes simultáneas. Estas pruebas permiten evaluar el rendimiento, tiempos de respuesta y estabilidad del sistema cuando procesa diversas acciones en paralelo \cite{LoadViewLoadTesting}.

\begin{itemize} 
\item \textbf{Objetivo:} Evaluar cómo responde el sistema bajo una carga esperada de usuarios o solicitudes simultáneas, enfocándose en el rendimiento y la estabilidad mientras se procesan múltiples acciones. \item \textbf{Resultado esperado:} Que el sistema mantenga tiempos de respuesta y niveles de rendimiento aceptables bajo condiciones de uso normales (es decir, el número máximo de usuarios esperados en condiciones típicas). 
\item \textbf{Prueba:} La prueba de carga implementada simula a varios usuarios ejecutando operaciones simultáneas, como autenticación, envío de videos y marcación de favoritos. Se registra el tiempo de respuesta y el estado de cada acción, evaluando así la capacidad de la aplicación para manejar un volumen esperado de usuarios sin degradar su rendimiento. 
\end{itemize}

Las pruebas de Extremo a Extremo (E2E) se orientan a evaluar el flujo completo de la aplicación desde la perspectiva del usuario. A diferencia de las pruebas de carga, estas pruebas verifican que todos los componentes del sistema funcionen conjuntamente como se espera en un caso de uso completo.

\begin{itemize} 
\item \textbf{Objetivo:} Confirmar que todas las partes de la aplicación funcionan de manera integrada y que los componentes interactúan correctamente en un flujo de uso completo. \item \textbf{Resultado esperado:} Que la aplicación ejecute todas las operaciones y flujos clave sin errores (por ejemplo, registro, autenticación, envío y consulta de datos), asegurando que las funcionalidades principales se integren de manera adecuada. 
\item \textbf{Prueba:} La prueba E2E implementada cubre un caso de uso completo, desde la creación de un usuario hasta la interacción con las principales funciones de la aplicación, como autenticación, carga de videos, traducción y manipulación de favoritos. Esta prueba garantiza que cada parte del sistema funcione en conjunto en el flujo real de un usuario. 
\end{itemize}

\section{Trabajo de campo}
Durante el proyecto, se tomó la decisión de no utilizar servicios en la nube como AWS o Azure debido al alto costo de sus equipos y servicios. En su lugar, se optó por utilizar los servidores disponibles en la UVG, específicamente el modelo DELL R740 ubicado en Jack’s Cave. Este equipo, que no poseía un sistema operativo preinstalado, fue configurado con Ubuntu Server 22.08, elegido por su versatilidad y disponibilidad gratuita. Este sistema operativo permitió la implementación de múltiples herramientas, incluyendo VPNs mediante OpenVPN siguiendo los pasos proporcionados por DigitalOcean \cite{digitalocean_openvpn}, lo que facilitaron el acceso remoto seguro al servidor.

El proceso de instalación incluyó la interacción con el controlador de RAID del servidor, el cual estaba gestionado por el controlador DELL PERC. Aunque RAID permite gestionar múltiples discos duros de manera eficiente, en este caso específico, donde solo se dispone de un disco duro de 1.92 TB, se decidió no utilizar el controlador RAID, ya que no ofrecía ventajas significativas para el sistema. En su lugar, el disco duro fue gestionado directamente, implementando mejoras manuales que ofrecían un rendimiento adecuado sin la complejidad adicional de RAID \cite{Raid}.

Tras la instalación del sistema operativo, se procedió a configurar OpenVPN para gestionar el acceso remoto al servidor. Los pasos seguidos incluyeron:
1. Generación y configuración de los materiales criptográficos necesarios, como claves y certificados, para garantizar una comunicación segura entre el servidor y los clientes.
2. Ajuste de la configuración de red de OpenVPN para la correcta distribución del tráfico de datos.
3. Configuración de las reglas de firewall necesarias para permitir el tráfico a través de la VPN sin comprometer la seguridad del sistema.
4. Inicio del servicio de OpenVPN y realización de pruebas para asegurar que las conexiones remotas funcionen correctamente \cite{OpenVPNSetup}.

